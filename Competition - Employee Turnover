import os
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from scipy.stats import skew
from sklearn.decomposition import PCA
'''
Data Manipulation/Feature Engineering:
'''
df = pd.read_csv('./data/employee_churn_data.csv') # (9540, 10)
#These columns are numeric:
cols=['promoted', 'review', 'projects', 'tenure', 
'satisfaction','bonus','avg_hrs_month']

y=df['left'].replace({'no': 0, 'yes': 1}).astype(int)
df=df.filter(cols).dropna()  #[9540 rows x 7 columns] #no missing values

#Finding Multicollinearity:
def printHeat():
    Var_Corr = df.corr()
    # plot the heatmap and annotation on it
    heat=sns.heatmap(Var_Corr, xticklabels=Var_Corr.columns, yticklabels=Var_Corr.columns, cmap='Greens', annot=True)
    print(heat)
'''
The heatmap shows a .98 correlation between avg_hrs_month and tenure
This was the only major Multicollinearity detected (above .80)  
Therefore, one of these variables should likely be removed
'''

#Calculating VIF
from statsmodels.stats.outliers_influence import variance_inflation_factor

def calc_vif(X):
    vif = pd.DataFrame()
    vif["variables"] = X.columns
    vif["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]
    return(vif)

calc=calc_vif(df[cols])
#print(calc)
'''
       variables         VIF
0       promoted    1.031462
1         review   71.424766
2       projects   32.971590
3         tenure   35.635391
4   satisfaction   13.329373
5          bonus    1.269142
6  avg_hrs_month  230.920778
'''


'''
Are the different correlations correlated? 
1)Normal correlation using .corr in Python. 
2)Pearson's correlation assesses linear relationships between two continuous variables.
3)Correlationn coefficient represents the linear dependence of two variables or sets of data.
'''
def printCor():
    dCor={} #correlation dictionary
    dPear={} #pearson dictionary 
    dCov={} #covariance correlation dictionary

    for col in cols:
        x=df[col] # each individual column

        #Correlation:
        cor=y.corr(x).round(3)
        dCor[col]=cor

        #pearson correlation:
        pear=np.corrcoef(list(x), list(y))[0, 1].round(3)
        dPear[col]=pear

        #covariance correlation
        cov=np.cov(x,y)[0][1].round(3)
        dCov[col]=cov

    #Sort dictionaries by highest correlation:
    dCor=sorted(((v, k) for k, v in dCor.items()), reverse=True)
    dPear=sorted(((v, k) for k, v in dPear.items()), reverse=True)
    dCov=sorted(((v, k) for k, v in dCov.items()), reverse=True)

    print("Calculating Correlations:")
    for d in dCor:
        print(d)
    print("")

    print("Calculate Pearson Correlation:")
    for p in dPear:
        print(p)
    print("")

    print("Covariance correlation:")
    for c in dCov:
        print(c)
    
'''
Calculating Correlations:
(0.304, 'review')
(0.011, 'tenure')
(0.009, 'avg_hrs_month')
(-0.01, 'satisfaction')
(-0.011, 'bonus')
(-0.012, 'projects')
(-0.037, 'promoted')

Calculate Pearson Correlation:
(0.304, 'review')
(0.011, 'tenure')
(0.009, 'avg_hrs_month')
(-0.01, 'satisfaction')
(-0.011, 'bonus')
(-0.012, 'projects')
(-0.037, 'promoted')

Covariance correlation:
(0.017, 'avg_hrs_month')
(0.012, 'review')
(0.007, 'tenure')
(-0.001, 'satisfaction')
(-0.002, 'bonus')
(-0.003, 'promoted')
(-0.003, 'projects')
'''



'''
LOGISTIC REGRESSION:
1)Train the model 
2)Generate predictions using AUC
'''
from sklearn.model_selection import train_test_split # splitting the data
from sklearn.linear_model import LogisticRegression # model algorithm
from sklearn import metrics

#Split the data set into x and y data:
y_data = np.asarray(y)
x_data = df[cols]

#split the dataset into training (70%) and testing (30%) sets:
from sklearn.model_selection import train_test_split
x_training_data, x_test_data, y_training_data, y_test_data = train_test_split(x_data, y_data, test_size = 0.3, random_state=42)
#Logistic regression defaults to L2

#Create the model
from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

#Train the model and create predictions
model.fit(x_training_data, y_training_data)
predictions = model.predict(x_test_data)
#print(predictions)

#GENERATE PREDICTION:
results=[] #store results that will later be turned into a DF.

#Calculate performance metrics
from sklearn.metrics import classification_report
#print(classification_report(y_test_data, predictions))

#Generate a confusion matrix
from sklearn.metrics import confusion_matrix, roc_auc_score

#use model to predict probability that given y value is 1:
y_pred_proba = model.predict_proba(x_test_data)[::,1]

#calculate AUC of model
results=[]
auc = round( metrics.roc_auc_score(y_test_data, y_pred_proba), 4 ) 
print("AUC is: ", auc, " using logistic regression.")
results.append(auc) #going to store results in a list
'''
AUC is:  0.7153 using logistic regression.
'''
